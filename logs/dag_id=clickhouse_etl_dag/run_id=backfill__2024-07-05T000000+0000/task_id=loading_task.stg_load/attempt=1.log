[2024-07-07T17:20:08.944+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-07T17:20:08.979+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: clickhouse_etl_dag.loading_task.stg_load backfill__2024-07-05T00:00:00+00:00 [queued]>
[2024-07-07T17:20:08.989+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: clickhouse_etl_dag.loading_task.stg_load backfill__2024-07-05T00:00:00+00:00 [queued]>
[2024-07-07T17:20:08.990+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 0
[2024-07-07T17:20:09.008+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): loading_task.stg_load> on 2024-07-05 00:00:00+00:00
[2024-07-07T17:20:09.015+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=2311) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-07T17:20:09.018+0000] {standard_task_runner.py:63} INFO - Started process 2322 to run task
[2024-07-07T17:20:09.018+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'clickhouse_etl_dag', 'loading_task.stg_load', 'backfill__2024-07-05T00:00:00+00:00', '--job-id', '64', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/clickhouse.py', '--cfg-path', '/tmp/tmp7s5zbjty']
[2024-07-07T17:20:09.020+0000] {standard_task_runner.py:91} INFO - Job 64: Subtask loading_task.stg_load
[2024-07-07T17:20:09.084+0000] {task_command.py:426} INFO - Running <TaskInstance: clickhouse_etl_dag.loading_task.stg_load backfill__2024-07-05T00:00:00+00:00 [running]> on host dfb367ef2d3b
[2024-07-07T17:20:09.195+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='franklinnwosu008@gmail.com' AIRFLOW_CTX_DAG_OWNER='Ifeanyi_DArTech_Org' AIRFLOW_CTX_DAG_ID='clickhouse_etl_dag' AIRFLOW_CTX_TASK_ID='loading_task.stg_load' AIRFLOW_CTX_EXECUTION_DATE='2024-07-05T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='backfill__2024-07-05T00:00:00+00:00'
[2024-07-07T17:20:09.197+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-07T17:20:09.249+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-07-07T17:20:09.250+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-07-07T17:20:09.708+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:09.797+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:09.852+0000] {cursor.py:1149} INFO - Number of results in first chunk: 7
[2024-07-07T17:20:09.902+0000] {cursor.py:1149} INFO - Number of results in first chunk: 7
[2024-07-07T17:20:09.992+0000] {cursor.py:1149} INFO - Number of results in first chunk: 2
[2024-07-07T17:20:10.061+0000] {cursor.py:1149} INFO - Number of results in first chunk: 0
[2024-07-07T17:20:10.110+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:10.171+0000] {cursor.py:1149} INFO - Number of results in first chunk: 0
[2024-07-07T17:20:12.625+0000] {cursor.py:1149} INFO - Number of results in first chunk: 10
[2024-07-07T17:20:12.703+0000] {cursor.py:1149} INFO - Number of results in first chunk: 0
[2024-07-07T17:20:12.782+0000] {cursor.py:1149} INFO - Number of results in first chunk: 0
[2024-07-07T17:20:12.870+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:13.051+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:13.109+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:13.110+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-07T17:20:13.112+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 002001 (02000): 01b58370-0000-534a-0000-0000d3318229: SQL compilation error:
Object 'TRIPDATA' does not exist or not authorized.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/modules/load.py", line 20, in load_csv_to_snowflake
    df.to_sql(table_name,con=engine, if_exists= 'replace', index=False, schema=schema)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/util/_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/core/generic.py", line 3008, in to_sql
    return sql.to_sql(
           ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 788, in to_sql
    return pandas_sql.to_sql(
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1948, in to_sql
    table = self.prep_table(
            ^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 1852, in prep_table
    table.create()
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 929, in create
    self.pd_sql.drop_table(self.name, self.schema)
  File "/home/airflow/.local/lib/python3.12/site-packages/pandas/io/sql.py", line 2003, in drop_table
    self.get_table(table_name, schema).drop(bind=self.con)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/schema.py", line 979, in drop
    bind._run_ddl_visitor(ddl.SchemaDropper, self, checkfirst=checkfirst)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2221, in _run_ddl_visitor
    visitorcallable(self.dialect, self, **kwargs).traverse_single(element)
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/visitors.py", line 524, in traverse_single
    return meth(obj, **kw)
           ^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py", line 1106, in visit_table
    self.connection.execute(DropTable(table))
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1385, in execute
    return meth(self, multiparams, params, _EMPTY_EXECUTION_OPTS)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/sql/ddl.py", line 80, in _execute_on_connection
    return connection._execute_ddl(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1477, in _execute_ddl
    ret = self._execute_context(
          ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1953, in _execute_context
    self._handle_dbapi_exception(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2134, in _handle_dbapi_exception
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 1910, in _execute_context
    self.dialect.do_execute(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 736, in do_execute
    cursor.execute(statement, parameters)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/cursor.py", line 1080, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 290, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 345, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.12/site-packages/snowflake/connector/errors.py", line 221, in default_errorhandler
    raise error_class(
sqlalchemy.exc.ProgrammingError: (snowflake.connector.errors.ProgrammingError) 002001 (02000): 01b58370-0000-534a-0000-0000d3318229: SQL compilation error:
Object 'TRIPDATA' does not exist or not authorized.
[SQL: 
DROP TABLE "STG".tripdata]
(Background on this error at: https://sqlalche.me/e/14/f405)
[2024-07-07T17:20:13.135+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=clickhouse_etl_dag, task_id=loading_task.stg_load, run_id=backfill__2024-07-05T00:00:00+00:00, execution_date=20240705T000000, start_date=20240707T172008, end_date=20240707T172013
[2024-07-07T17:20:13.157+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 64 for task loading_task.stg_load ((snowflake.connector.errors.ProgrammingError) 002001 (02000): 01b58370-0000-534a-0000-0000d3318229: SQL compilation error:
Object 'TRIPDATA' does not exist or not authorized.
[SQL: 
DROP TABLE "STG".tripdata]
(Background on this error at: https://sqlalche.me/e/14/f405); 2322)
[2024-07-07T17:20:13.212+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-07-07T17:20:13.228+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
