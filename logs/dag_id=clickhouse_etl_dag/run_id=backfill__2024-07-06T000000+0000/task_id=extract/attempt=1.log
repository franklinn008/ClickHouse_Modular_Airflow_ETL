[2024-07-07T17:19:58.964+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-07T17:19:59.014+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: clickhouse_etl_dag.extract backfill__2024-07-06T00:00:00+00:00 [queued]>
[2024-07-07T17:19:59.029+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: clickhouse_etl_dag.extract backfill__2024-07-06T00:00:00+00:00 [queued]>
[2024-07-07T17:19:59.030+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 0
[2024-07-07T17:19:59.060+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): extract> on 2024-07-06 00:00:00+00:00
[2024-07-07T17:19:59.078+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=2293) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-07T17:19:59.081+0000] {standard_task_runner.py:63} INFO - Started process 2303 to run task
[2024-07-07T17:19:59.082+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'clickhouse_etl_dag', 'extract', 'backfill__2024-07-06T00:00:00+00:00', '--job-id', '57', '--pool', 'default_pool', '--raw', '--subdir', 'DAGS_FOLDER/clickhouse.py', '--cfg-path', '/tmp/tmpkg3_p9vt']
[2024-07-07T17:19:59.083+0000] {standard_task_runner.py:91} INFO - Job 57: Subtask extract
[2024-07-07T17:19:59.163+0000] {task_command.py:426} INFO - Running <TaskInstance: clickhouse_etl_dag.extract backfill__2024-07-06T00:00:00+00:00 [running]> on host dfb367ef2d3b
[2024-07-07T17:19:59.328+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='franklinnwosu008@gmail.com' AIRFLOW_CTX_DAG_OWNER='Ifeanyi_DArTech_Org' AIRFLOW_CTX_DAG_ID='clickhouse_etl_dag' AIRFLOW_CTX_TASK_ID='extract' AIRFLOW_CTX_EXECUTION_DATE='2024-07-06T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='backfill__2024-07-06T00:00:00+00:00'
[2024-07-07T17:19:59.331+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-07T17:19:59.355+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-07-07T17:19:59.356+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-07-07T17:19:59.982+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:00.058+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:00.527+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:00.580+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:00.649+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T17:20:00.651+0000] {logging_mixin.py:188} INFO - 2015-01-04
[2024-07-07T17:20:01.116+0000] {logging_mixin.py:188} INFO - 7032 rows successfully extracted for 2015-01-05 
[2024-07-07T17:20:01.119+0000] {python.py:237} INFO - Done. Returned value was: None
[2024-07-07T17:20:01.121+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-07T17:20:01.147+0000] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=clickhouse_etl_dag, task_id=extract, run_id=backfill__2024-07-06T00:00:00+00:00, execution_date=20240706T000000, start_date=20240707T171959, end_date=20240707T172001
[2024-07-07T17:20:01.234+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-07T17:20:01.389+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
