[2024-07-07T14:49:47.704+0000] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-07T14:49:47.752+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: clickhouse_etl_dag.extract manual__2024-07-07T14:49:42.273760+00:00 [queued]>
[2024-07-07T14:49:47.771+0000] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: clickhouse_etl_dag.extract manual__2024-07-07T14:49:42.273760+00:00 [queued]>
[2024-07-07T14:49:47.775+0000] {taskinstance.py:2306} INFO - Starting attempt 1 of 0
[2024-07-07T14:49:47.805+0000] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): extract> on 2024-07-07 14:49:42.273760+00:00
[2024-07-07T14:49:47.825+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:61: DeprecationWarning: This process (pid=684) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2024-07-07T14:49:47.828+0000] {standard_task_runner.py:63} INFO - Started process 686 to run task
[2024-07-07T14:49:47.832+0000] {standard_task_runner.py:90} INFO - Running: ['***', 'tasks', 'run', 'clickhouse_etl_dag', 'extract', 'manual__2024-07-07T14:49:42.273760+00:00', '--job-id', '43', '--raw', '--subdir', 'DAGS_FOLDER/clickhouse.py', '--cfg-path', '/tmp/tmpbc3iz1_j']
[2024-07-07T14:49:47.835+0000] {standard_task_runner.py:91} INFO - Job 43: Subtask extract
[2024-07-07T14:49:47.932+0000] {task_command.py:426} INFO - Running <TaskInstance: clickhouse_etl_dag.extract manual__2024-07-07T14:49:42.273760+00:00 [running]> on host dfb367ef2d3b
[2024-07-07T14:49:48.108+0000] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_EMAIL='franklinnwosu008@gmail.com' AIRFLOW_CTX_DAG_OWNER='Ifeanyi_DArTech_Org' AIRFLOW_CTX_DAG_ID='clickhouse_etl_dag' AIRFLOW_CTX_TASK_ID='extract' AIRFLOW_CTX_EXECUTION_DATE='2024-07-07T14:49:42.273760+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-07-07T14:49:42.273760+00:00'
[2024-07-07T14:49:48.113+0000] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-07T14:49:48.141+0000] {connection.py:399} INFO - Snowflake Connector for Python Version: 3.10.1, Python Version: 3.12.4, Platform: Linux-5.15.153.1-microsoft-standard-WSL2-x86_64-with-glibc2.36
[2024-07-07T14:49:48.144+0000] {connection.py:1239} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-07-07T14:49:48.766+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T14:49:48.861+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T14:49:48.933+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T14:49:49.002+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T14:49:49.060+0000] {cursor.py:1149} INFO - Number of results in first chunk: 1
[2024-07-07T14:49:49.062+0000] {logging_mixin.py:188} INFO - 2015-01-02
[2024-07-07T14:49:49.188+0000] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-07T14:49:49.189+0000] {taskinstance.py:2905} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 465, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 432, in _execute_callable
    return execute_callable(context=context, **execute_callable_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 401, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 235, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 252, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/modules/extract.py", line 40, in fetch_data
    output = client.query(query)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/client.py", line 208, in query
    return self._query_with_context(query_context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 219, in _query_with_context
    response = self._raw_request(body,
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 448, in _raw_request
    self._error_handler(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/clickhouse_connect/driver/httpclient.py", line 371, in _error_handler
    raise OperationalError(err_str) if retried else DatabaseError(err_str) from None
clickhouse_connect.driver.exceptions.DatabaseError: HTTPDriver for https://github.demo.trial.altinity.cloud:8443 returned response code 400)
 Code: 38. DB::Exception: Cannot parse date here: {max_date}: Cannot parse Date from String: In scope SELECT pickup_date, vendor_id, passenger_count, trip_distance, payment_type, fare_amount, tip_amount FROM tripdata WHERE pickup_date = (toDate('{max_date}') + toIntervalDay(1)). (CANNOT_PARSE_DATE) (version 24.5.3.5 (official build))

[2024-07-07T14:49:49.224+0000] {taskinstance.py:1206} INFO - Marking task as FAILED. dag_id=clickhouse_etl_dag, task_id=extract, run_id=manual__2024-07-07T14:49:42.273760+00:00, execution_date=20240707T144942, start_date=20240707T144947, end_date=20240707T144949
[2024-07-07T14:49:49.266+0000] {standard_task_runner.py:110} ERROR - Failed to execute job 43 for task extract (HTTPDriver for https://github.demo.trial.altinity.cloud:8443 returned response code 400)
 Code: 38. DB::Exception: Cannot parse date here: {max_date}: Cannot parse Date from String: In scope SELECT pickup_date, vendor_id, passenger_count, trip_distance, payment_type, fare_amount, tip_amount FROM tripdata WHERE pickup_date = (toDate('{max_date}') + toIntervalDay(1)). (CANNOT_PARSE_DATE) (version 24.5.3.5 (official build))
; 686)
[2024-07-07T14:49:49.293+0000] {local_task_job_runner.py:240} INFO - Task exited with return code 1
[2024-07-07T14:49:49.319+0000] {local_task_job_runner.py:222} INFO - ::endgroup::
